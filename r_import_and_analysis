# PURPOSE: To import a large amount of email data into R and  create
# some histograms that reveal the distribution of email events over time.
# USAGE: Written to be run in an R console. 
# BUG: Will not work with larger datasets, since here we slurp the whole
# thing into R.


library(dplyr)
library(purrr)

# Import the csv file into R, creating a new dataframe.
email_data <- read.csv("FILENAME")

# Coerce the values to POSIX format. There are missing values in the
# first_attempt column, so we need to be careful with that.
email_data$created <- as.POSIXct(email_data$created)
email_data$final_attempt <- as.POSIXct(email_data$final_attempt)
email_data$first_attempt <- sub("^$", NA, email_data$first_attempt)
email_data$first_attempt <- as.POSIXct(email_data$first_attempt, na.rm = TRUE)

# Create histograms for each variable, playing with the bin size to see
# which one gives the best view of our data. 
hist(email_data$created, breaks = 50)
hist(email_data$created, breaks = 75)
hist(email_data$created, breaks = 100)

hist(email_data$first_attempt, breaks = 50)
hist(email_data$first_attempt, breaks = 75)
hist(email_data$first_attempt, breaks = 100)

hist(email_data$final_attempt, breaks = 50)
hist(email_data$final_attempt, breaks = 75)
hist(email_data$final_attempt, breaks = 100)

# Create a new data frame whose rows represent the bins from email_data. 
# For now we do this for just one variable. 
tmp <- hist(email_data$created, breaks = 50)
email_data_created_50 <- mutate(email_data, bin_number = findInterval(email_data$created, tmp$breaks)) %>% 
	group_by(bin_number) %>%
		summarize(num_in_bin = n())

# email_data_created_50 conveniently shrinks our original thousands of
# lines of data into just 50. As long as what we care about is the 
# distribution of events over time, this is fine.



